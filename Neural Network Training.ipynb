{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210ab84a-1e92-4c7d-8e72-cac6504273da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd58fce-e165-4043-b5cd-62cccb4b1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_path = './Training Set'\n",
    "test_dataset_path = './Test Set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467c3d92-2e95-482e-baf9-bce8d2a0d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.4243, 0.4522, 0.5050]\n",
    "std = [0.2150, 0.2035, 0.1913]\n",
    "\n",
    "training_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)), # Tweak this later on to determine best size\n",
    "    transforms.RandomHorizontalFlip(), # Depends on the data, experiment here again\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d4e302-dc45-4c37-8dd6-f9e8460ef087",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = torchvision.datasets.ImageFolder(root = training_dataset_path, transform = training_transforms)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = test_dataset_path, transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a5d84f-8982-43e9-966e-864739e52728",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True) # shuffled for better generalization\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False) # Not shuffled since actual comparison data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722dc8d5-4d1d-4980-83e0-1b4c3d12504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = \"cuda:0\"\n",
    "    else:\n",
    "        dev = \"cpu\"\n",
    "    return torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea777b6-9262-4b3f-97ed-3e1d519318fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model = models.resnet18()\n",
    "num_ftrs = resnet18_model.fc.in_features\n",
    "num_classes = 6\n",
    "resnet18_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "device = set_device()\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss() # Measures the error of the model\n",
    "\n",
    "# SGD = Stochastic Gradient Descent (will apply Mini Gradient Descent)\n",
    "# lr = learning rate (how much model will change in response to error)\n",
    "# momentum (accelerates gradient vectors in the right direction)\n",
    "# weight_decay (gives extra error for incorrect prediction, reduces overfitting)\n",
    "\n",
    "optimizer = optim.SGD(resnet18_model.parameters(),lr=0.01, momentum=0.9, weight_decay=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1bde81-913a-481a-96c1-6f6f0ce71610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, training_loader, test_loader, criterion, optimizer, n_epochs):\n",
    "    device = set_device()\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch number: {epoch+1}') # placeholder value syntax\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in training_loader:\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device) # using CUDA if available instead of CPU\n",
    "            total += labels.size(0) # size(0) contains batch size\n",
    "\n",
    "            optimizer.zero_grad() # sets gradients to 0 (math stuff I dont understand)\n",
    "            outputs = model(images) # model returns raw scores representing predictions\n",
    "            _, predicted = torch.max(outputs.data, 1) # Extracts the most likely class label \n",
    "            loss = criterion(outputs, labels) # Compares outputs (what the model classified) and labels (actual value) with the CEL func\n",
    "            loss.backward() # backpropagation\n",
    "            optimizer.step() # update weights\n",
    "\n",
    "            running_loss += loss.item() # Adds loss value, which is just a reference decimal to overall accuracy\n",
    "            running_correct += (predicted==labels).sum().item() # Creates true/false tensor, and adds their binary values to give correct predictions count\n",
    "\n",
    "        epoch_loss = running_loss/len(training_loader) # Divides running_loss over number of batches in epoch\n",
    "        epoch_accuracy = 100 * running_correct/total\n",
    "    \n",
    "        print(f'   -Training: {running_correct} images predicted correctly out of {total} (Accuracy: {epoch_accuracy:.3f}%, Epoch Loss: {epoch_loss:.3f}%)') \n",
    "        \n",
    "        test_accuracy = evaluate_model_on_test_set(model, test_loader)\n",
    "        \n",
    "        if(test_accuracy>best_accuracy):\n",
    "            best_accuracy = test_accuracy\n",
    "            save_checkpoint(model, epoch, optimizer, best_accuracy)\n",
    "        \n",
    "    print('Finished')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e04ff26-3cc2-473b-bd92-c3735139d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test_set(model, test_loader):\n",
    "    model.eval() # sets model to evaluate mode\n",
    "    epoch_correct_predictions = 0 # initiliazied counter\n",
    "    total = 0 # initialized counter\n",
    "    device = set_device() # CPU -> GPU\n",
    "    \n",
    "    with torch.no_grad(): # disables gradient descent, not allowing backpropagation (not needed here) and it saves memory and time\n",
    "        for batch in test_loader:\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            outputs = model(images) \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            epoch_correct_predictions += (predicted==labels).sum().item()\n",
    "\n",
    "    epoch_accuracy = 100 * epoch_correct_predictions/total\n",
    "    \n",
    "    print(f'   -Testing: {epoch_correct_predictions} images predicted correctly out of {total} (Accuracy: {epoch_accuracy:.3f})%') \n",
    "\n",
    "    return epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ddaa43-45eb-4b5d-af3c-6599ed75e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch, optimizer, accuracy):\n",
    "    # creates a state dictionary containing information of current model iteration\n",
    "    state = {\n",
    "        'epoch': epoch+1,\n",
    "        'model' : model.state_dict(), # creates another state dictionary containing learned parameters of the model\n",
    "        'accuracy' : accuracy,\n",
    "        'optimizer': optimizer.state_dict() # creates another state dictionary containing optimizer information (lr,momentum, weight_decay)\n",
    "    }\n",
    "    torch.save(state, 'Best-Model-Checkpoint.pth.tar')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9dbaf52-8e11-4363-b141-20d9759245cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1\n",
      "   -Training: 233.0 images predicted correctly out of 691 (Accuracy: 33.719%, Epoch Loss: 1.676%)\n",
      "   -Testing: 69 images predicted correctly out of 194 (Accuracy: 35.567)%\n",
      "Epoch number: 2\n",
      "   -Training: 355.0 images predicted correctly out of 691 (Accuracy: 51.375%, Epoch Loss: 1.338%)\n",
      "   -Testing: 90 images predicted correctly out of 194 (Accuracy: 46.392)%\n",
      "Epoch number: 3\n",
      "   -Training: 375.0 images predicted correctly out of 691 (Accuracy: 54.269%, Epoch Loss: 1.307%)\n",
      "   -Testing: 60 images predicted correctly out of 194 (Accuracy: 30.928)%\n",
      "Epoch number: 4\n",
      "   -Training: 385.0 images predicted correctly out of 691 (Accuracy: 55.716%, Epoch Loss: 1.339%)\n",
      "   -Testing: 101 images predicted correctly out of 194 (Accuracy: 52.062)%\n",
      "Epoch number: 5\n",
      "   -Training: 410.0 images predicted correctly out of 691 (Accuracy: 59.334%, Epoch Loss: 1.122%)\n",
      "   -Testing: 89 images predicted correctly out of 194 (Accuracy: 45.876)%\n",
      "Epoch number: 6\n",
      "   -Training: 430.0 images predicted correctly out of 691 (Accuracy: 62.229%, Epoch Loss: 1.011%)\n",
      "   -Testing: 63 images predicted correctly out of 194 (Accuracy: 32.474)%\n",
      "Epoch number: 7\n",
      "   -Training: 458.0 images predicted correctly out of 691 (Accuracy: 66.281%, Epoch Loss: 1.034%)\n",
      "   -Testing: 106 images predicted correctly out of 194 (Accuracy: 54.639)%\n",
      "Epoch number: 8\n",
      "   -Training: 462.0 images predicted correctly out of 691 (Accuracy: 66.860%, Epoch Loss: 0.993%)\n",
      "   -Testing: 84 images predicted correctly out of 194 (Accuracy: 43.299)%\n",
      "Epoch number: 9\n",
      "   -Training: 482.0 images predicted correctly out of 691 (Accuracy: 69.754%, Epoch Loss: 0.925%)\n",
      "   -Testing: 108 images predicted correctly out of 194 (Accuracy: 55.670)%\n",
      "Epoch number: 10\n",
      "   -Training: 493.0 images predicted correctly out of 691 (Accuracy: 71.346%, Epoch Loss: 0.780%)\n",
      "   -Testing: 120 images predicted correctly out of 194 (Accuracy: 61.856)%\n",
      "Epoch number: 11\n",
      "   -Training: 506.0 images predicted correctly out of 691 (Accuracy: 73.227%, Epoch Loss: 0.775%)\n",
      "   -Testing: 117 images predicted correctly out of 194 (Accuracy: 60.309)%\n",
      "Epoch number: 12\n",
      "   -Training: 510.0 images predicted correctly out of 691 (Accuracy: 73.806%, Epoch Loss: 0.820%)\n",
      "   -Testing: 105 images predicted correctly out of 194 (Accuracy: 54.124)%\n",
      "Epoch number: 13\n",
      "   -Training: 522.0 images predicted correctly out of 691 (Accuracy: 75.543%, Epoch Loss: 0.678%)\n",
      "   -Testing: 119 images predicted correctly out of 194 (Accuracy: 61.340)%\n",
      "Epoch number: 14\n",
      "   -Training: 535.0 images predicted correctly out of 691 (Accuracy: 77.424%, Epoch Loss: 0.676%)\n",
      "   -Testing: 112 images predicted correctly out of 194 (Accuracy: 57.732)%\n",
      "Epoch number: 15\n",
      "   -Training: 530.0 images predicted correctly out of 691 (Accuracy: 76.700%, Epoch Loss: 0.666%)\n",
      "   -Testing: 108 images predicted correctly out of 194 (Accuracy: 55.670)%\n",
      "Epoch number: 16\n",
      "   -Training: 538.0 images predicted correctly out of 691 (Accuracy: 77.858%, Epoch Loss: 0.642%)\n",
      "   -Testing: 89 images predicted correctly out of 194 (Accuracy: 45.876)%\n",
      "Epoch number: 17\n",
      "   -Training: 549.0 images predicted correctly out of 691 (Accuracy: 79.450%, Epoch Loss: 0.597%)\n",
      "   -Testing: 109 images predicted correctly out of 194 (Accuracy: 56.186)%\n",
      "Epoch number: 18\n",
      "   -Training: 581.0 images predicted correctly out of 691 (Accuracy: 84.081%, Epoch Loss: 0.450%)\n",
      "   -Testing: 124 images predicted correctly out of 194 (Accuracy: 63.918)%\n",
      "Epoch number: 19\n",
      "   -Training: 585.0 images predicted correctly out of 691 (Accuracy: 84.660%, Epoch Loss: 0.493%)\n",
      "   -Testing: 116 images predicted correctly out of 194 (Accuracy: 59.794)%\n",
      "Epoch number: 20\n",
      "   -Training: 588.0 images predicted correctly out of 691 (Accuracy: 85.094%, Epoch Loss: 0.423%)\n",
      "   -Testing: 119 images predicted correctly out of 194 (Accuracy: 61.340)%\n",
      "Epoch number: 21\n",
      "   -Training: 586.0 images predicted correctly out of 691 (Accuracy: 84.805%, Epoch Loss: 0.374%)\n",
      "   -Testing: 109 images predicted correctly out of 194 (Accuracy: 56.186)%\n",
      "Epoch number: 22\n",
      "   -Training: 586.0 images predicted correctly out of 691 (Accuracy: 84.805%, Epoch Loss: 0.418%)\n",
      "   -Testing: 122 images predicted correctly out of 194 (Accuracy: 62.887)%\n",
      "Epoch number: 23\n",
      "   -Training: 600.0 images predicted correctly out of 691 (Accuracy: 86.831%, Epoch Loss: 0.365%)\n",
      "   -Testing: 131 images predicted correctly out of 194 (Accuracy: 67.526)%\n",
      "Epoch number: 24\n",
      "   -Training: 603.0 images predicted correctly out of 691 (Accuracy: 87.265%, Epoch Loss: 0.352%)\n",
      "   -Testing: 123 images predicted correctly out of 194 (Accuracy: 63.402)%\n",
      "Epoch number: 25\n",
      "   -Training: 626.0 images predicted correctly out of 691 (Accuracy: 90.593%, Epoch Loss: 0.286%)\n",
      "   -Testing: 133 images predicted correctly out of 194 (Accuracy: 68.557)%\n",
      "Epoch number: 26\n",
      "   -Training: 600.0 images predicted correctly out of 691 (Accuracy: 86.831%, Epoch Loss: 0.347%)\n",
      "   -Testing: 122 images predicted correctly out of 194 (Accuracy: 62.887)%\n",
      "Epoch number: 27\n",
      "   -Training: 635.0 images predicted correctly out of 691 (Accuracy: 91.896%, Epoch Loss: 0.226%)\n",
      "   -Testing: 125 images predicted correctly out of 194 (Accuracy: 64.433)%\n",
      "Epoch number: 28\n",
      "   -Training: 617.0 images predicted correctly out of 691 (Accuracy: 89.291%, Epoch Loss: 0.325%)\n",
      "   -Testing: 104 images predicted correctly out of 194 (Accuracy: 53.608)%\n",
      "Epoch number: 29\n",
      "   -Training: 587.0 images predicted correctly out of 691 (Accuracy: 84.949%, Epoch Loss: 0.392%)\n",
      "   -Testing: 110 images predicted correctly out of 194 (Accuracy: 56.701)%\n",
      "Epoch number: 30\n",
      "   -Training: 622.0 images predicted correctly out of 691 (Accuracy: 90.014%, Epoch Loss: 0.290%)\n",
      "   -Testing: 135 images predicted correctly out of 194 (Accuracy: 69.588)%\n",
      "Epoch number: 31\n",
      "   -Training: 631.0 images predicted correctly out of 691 (Accuracy: 91.317%, Epoch Loss: 0.256%)\n",
      "   -Testing: 115 images predicted correctly out of 194 (Accuracy: 59.278)%\n",
      "Epoch number: 32\n",
      "   -Training: 634.0 images predicted correctly out of 691 (Accuracy: 91.751%, Epoch Loss: 0.251%)\n",
      "   -Testing: 126 images predicted correctly out of 194 (Accuracy: 64.948)%\n",
      "Epoch number: 33\n",
      "   -Training: 643.0 images predicted correctly out of 691 (Accuracy: 93.054%, Epoch Loss: 0.181%)\n",
      "   -Testing: 131 images predicted correctly out of 194 (Accuracy: 67.526)%\n",
      "Epoch number: 34\n",
      "   -Training: 663.0 images predicted correctly out of 691 (Accuracy: 95.948%, Epoch Loss: 0.142%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 35\n",
      "   -Training: 658.0 images predicted correctly out of 691 (Accuracy: 95.224%, Epoch Loss: 0.151%)\n",
      "   -Testing: 137 images predicted correctly out of 194 (Accuracy: 70.619)%\n",
      "Epoch number: 36\n",
      "   -Training: 634.0 images predicted correctly out of 691 (Accuracy: 91.751%, Epoch Loss: 0.216%)\n",
      "   -Testing: 132 images predicted correctly out of 194 (Accuracy: 68.041)%\n",
      "Epoch number: 37\n",
      "   -Training: 646.0 images predicted correctly out of 691 (Accuracy: 93.488%, Epoch Loss: 0.185%)\n",
      "   -Testing: 120 images predicted correctly out of 194 (Accuracy: 61.856)%\n",
      "Epoch number: 38\n",
      "   -Training: 623.0 images predicted correctly out of 691 (Accuracy: 90.159%, Epoch Loss: 0.272%)\n",
      "   -Testing: 125 images predicted correctly out of 194 (Accuracy: 64.433)%\n",
      "Epoch number: 39\n",
      "   -Training: 645.0 images predicted correctly out of 691 (Accuracy: 93.343%, Epoch Loss: 0.196%)\n",
      "   -Testing: 127 images predicted correctly out of 194 (Accuracy: 65.464)%\n",
      "Epoch number: 40\n",
      "   -Training: 636.0 images predicted correctly out of 691 (Accuracy: 92.041%, Epoch Loss: 0.215%)\n",
      "   -Testing: 121 images predicted correctly out of 194 (Accuracy: 62.371)%\n",
      "Epoch number: 41\n",
      "   -Training: 651.0 images predicted correctly out of 691 (Accuracy: 94.211%, Epoch Loss: 0.164%)\n",
      "   -Testing: 131 images predicted correctly out of 194 (Accuracy: 67.526)%\n",
      "Epoch number: 42\n",
      "   -Training: 642.0 images predicted correctly out of 691 (Accuracy: 92.909%, Epoch Loss: 0.208%)\n",
      "   -Testing: 130 images predicted correctly out of 194 (Accuracy: 67.010)%\n",
      "Epoch number: 43\n",
      "   -Training: 653.0 images predicted correctly out of 691 (Accuracy: 94.501%, Epoch Loss: 0.150%)\n",
      "   -Testing: 147 images predicted correctly out of 194 (Accuracy: 75.773)%\n",
      "Epoch number: 44\n",
      "   -Training: 651.0 images predicted correctly out of 691 (Accuracy: 94.211%, Epoch Loss: 0.174%)\n",
      "   -Testing: 134 images predicted correctly out of 194 (Accuracy: 69.072)%\n",
      "Epoch number: 45\n",
      "   -Training: 659.0 images predicted correctly out of 691 (Accuracy: 95.369%, Epoch Loss: 0.135%)\n",
      "   -Testing: 123 images predicted correctly out of 194 (Accuracy: 63.402)%\n",
      "Epoch number: 46\n",
      "   -Training: 676.0 images predicted correctly out of 691 (Accuracy: 97.829%, Epoch Loss: 0.091%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 47\n",
      "   -Training: 675.0 images predicted correctly out of 691 (Accuracy: 97.685%, Epoch Loss: 0.084%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 48\n",
      "   -Training: 680.0 images predicted correctly out of 691 (Accuracy: 98.408%, Epoch Loss: 0.065%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 49\n",
      "   -Training: 675.0 images predicted correctly out of 691 (Accuracy: 97.685%, Epoch Loss: 0.066%)\n",
      "   -Testing: 137 images predicted correctly out of 194 (Accuracy: 70.619)%\n",
      "Epoch number: 50\n",
      "   -Training: 672.0 images predicted correctly out of 691 (Accuracy: 97.250%, Epoch Loss: 0.119%)\n",
      "   -Testing: 134 images predicted correctly out of 194 (Accuracy: 69.072)%\n",
      "Epoch number: 51\n",
      "   -Training: 660.0 images predicted correctly out of 691 (Accuracy: 95.514%, Epoch Loss: 0.119%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 52\n",
      "   -Training: 662.0 images predicted correctly out of 691 (Accuracy: 95.803%, Epoch Loss: 0.111%)\n",
      "   -Testing: 126 images predicted correctly out of 194 (Accuracy: 64.948)%\n",
      "Epoch number: 53\n",
      "   -Training: 665.0 images predicted correctly out of 691 (Accuracy: 96.237%, Epoch Loss: 0.096%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 54\n",
      "   -Training: 662.0 images predicted correctly out of 691 (Accuracy: 95.803%, Epoch Loss: 0.117%)\n",
      "   -Testing: 135 images predicted correctly out of 194 (Accuracy: 69.588)%\n",
      "Epoch number: 55\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.059%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 56\n",
      "   -Training: 677.0 images predicted correctly out of 691 (Accuracy: 97.974%, Epoch Loss: 0.067%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 57\n",
      "   -Training: 671.0 images predicted correctly out of 691 (Accuracy: 97.106%, Epoch Loss: 0.097%)\n",
      "   -Testing: 128 images predicted correctly out of 194 (Accuracy: 65.979)%\n",
      "Epoch number: 58\n",
      "   -Training: 673.0 images predicted correctly out of 691 (Accuracy: 97.395%, Epoch Loss: 0.078%)\n",
      "   -Testing: 119 images predicted correctly out of 194 (Accuracy: 61.340)%\n",
      "Epoch number: 59\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.049%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 60\n",
      "   -Training: 680.0 images predicted correctly out of 691 (Accuracy: 98.408%, Epoch Loss: 0.056%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 61\n",
      "   -Training: 680.0 images predicted correctly out of 691 (Accuracy: 98.408%, Epoch Loss: 0.057%)\n",
      "   -Testing: 145 images predicted correctly out of 194 (Accuracy: 74.742)%\n",
      "Epoch number: 62\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.050%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 63\n",
      "   -Training: 683.0 images predicted correctly out of 691 (Accuracy: 98.842%, Epoch Loss: 0.042%)\n",
      "   -Testing: 137 images predicted correctly out of 194 (Accuracy: 70.619)%\n",
      "Epoch number: 64\n",
      "   -Training: 676.0 images predicted correctly out of 691 (Accuracy: 97.829%, Epoch Loss: 0.070%)\n",
      "   -Testing: 127 images predicted correctly out of 194 (Accuracy: 65.464)%\n",
      "Epoch number: 65\n",
      "   -Training: 679.0 images predicted correctly out of 691 (Accuracy: 98.263%, Epoch Loss: 0.075%)\n",
      "   -Testing: 137 images predicted correctly out of 194 (Accuracy: 70.619)%\n",
      "Epoch number: 66\n",
      "   -Training: 676.0 images predicted correctly out of 691 (Accuracy: 97.829%, Epoch Loss: 0.076%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 67\n",
      "   -Training: 670.0 images predicted correctly out of 691 (Accuracy: 96.961%, Epoch Loss: 0.090%)\n",
      "   -Testing: 133 images predicted correctly out of 194 (Accuracy: 68.557)%\n",
      "Epoch number: 68\n",
      "   -Training: 665.0 images predicted correctly out of 691 (Accuracy: 96.237%, Epoch Loss: 0.090%)\n",
      "   -Testing: 127 images predicted correctly out of 194 (Accuracy: 65.464)%\n",
      "Epoch number: 69\n",
      "   -Training: 652.0 images predicted correctly out of 691 (Accuracy: 94.356%, Epoch Loss: 0.143%)\n",
      "   -Testing: 126 images predicted correctly out of 194 (Accuracy: 64.948)%\n",
      "Epoch number: 70\n",
      "   -Training: 659.0 images predicted correctly out of 691 (Accuracy: 95.369%, Epoch Loss: 0.148%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 71\n",
      "   -Training: 665.0 images predicted correctly out of 691 (Accuracy: 96.237%, Epoch Loss: 0.109%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 72\n",
      "   -Training: 652.0 images predicted correctly out of 691 (Accuracy: 94.356%, Epoch Loss: 0.159%)\n",
      "   -Testing: 134 images predicted correctly out of 194 (Accuracy: 69.072)%\n",
      "Epoch number: 73\n",
      "   -Training: 650.0 images predicted correctly out of 691 (Accuracy: 94.067%, Epoch Loss: 0.171%)\n",
      "   -Testing: 133 images predicted correctly out of 194 (Accuracy: 68.557)%\n",
      "Epoch number: 74\n",
      "   -Training: 661.0 images predicted correctly out of 691 (Accuracy: 95.658%, Epoch Loss: 0.127%)\n",
      "   -Testing: 125 images predicted correctly out of 194 (Accuracy: 64.433)%\n",
      "Epoch number: 75\n",
      "   -Training: 662.0 images predicted correctly out of 691 (Accuracy: 95.803%, Epoch Loss: 0.128%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 76\n",
      "   -Training: 670.0 images predicted correctly out of 691 (Accuracy: 96.961%, Epoch Loss: 0.101%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 77\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.062%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 78\n",
      "   -Training: 679.0 images predicted correctly out of 691 (Accuracy: 98.263%, Epoch Loss: 0.068%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 79\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.037%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 80\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.036%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 81\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.030%)\n",
      "   -Testing: 146 images predicted correctly out of 194 (Accuracy: 75.258)%\n",
      "Epoch number: 82\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.025%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 83\n",
      "   -Training: 689.0 images predicted correctly out of 691 (Accuracy: 99.711%, Epoch Loss: 0.026%)\n",
      "   -Testing: 147 images predicted correctly out of 194 (Accuracy: 75.773)%\n",
      "Epoch number: 84\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.020%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 85\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.019%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 86\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.017%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 87\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.023%)\n",
      "   -Testing: 144 images predicted correctly out of 194 (Accuracy: 74.227)%\n",
      "Epoch number: 88\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.029%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 89\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.038%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 90\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.040%)\n",
      "   -Testing: 130 images predicted correctly out of 194 (Accuracy: 67.010)%\n",
      "Epoch number: 91\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.020%)\n",
      "   -Testing: 147 images predicted correctly out of 194 (Accuracy: 75.773)%\n",
      "Epoch number: 92\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.022%)\n",
      "   -Testing: 148 images predicted correctly out of 194 (Accuracy: 76.289)%\n",
      "Epoch number: 93\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.029%)\n",
      "   -Testing: 142 images predicted correctly out of 194 (Accuracy: 73.196)%\n",
      "Epoch number: 94\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.018%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 95\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.017%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 96\n",
      "   -Training: 689.0 images predicted correctly out of 691 (Accuracy: 99.711%, Epoch Loss: 0.022%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 97\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.023%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 98\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.028%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 99\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.032%)\n",
      "   -Testing: 133 images predicted correctly out of 194 (Accuracy: 68.557)%\n",
      "Epoch number: 100\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.031%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 101\n",
      "   -Training: 682.0 images predicted correctly out of 691 (Accuracy: 98.698%, Epoch Loss: 0.035%)\n",
      "   -Testing: 134 images predicted correctly out of 194 (Accuracy: 69.072)%\n",
      "Epoch number: 102\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.034%)\n",
      "   -Testing: 133 images predicted correctly out of 194 (Accuracy: 68.557)%\n",
      "Epoch number: 103\n",
      "   -Training: 678.0 images predicted correctly out of 691 (Accuracy: 98.119%, Epoch Loss: 0.061%)\n",
      "   -Testing: 123 images predicted correctly out of 194 (Accuracy: 63.402)%\n",
      "Epoch number: 104\n",
      "   -Training: 671.0 images predicted correctly out of 691 (Accuracy: 97.106%, Epoch Loss: 0.090%)\n",
      "   -Testing: 129 images predicted correctly out of 194 (Accuracy: 66.495)%\n",
      "Epoch number: 105\n",
      "   -Training: 672.0 images predicted correctly out of 691 (Accuracy: 97.250%, Epoch Loss: 0.086%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 106\n",
      "   -Training: 669.0 images predicted correctly out of 691 (Accuracy: 96.816%, Epoch Loss: 0.103%)\n",
      "   -Testing: 127 images predicted correctly out of 194 (Accuracy: 65.464)%\n",
      "Epoch number: 107\n",
      "   -Training: 676.0 images predicted correctly out of 691 (Accuracy: 97.829%, Epoch Loss: 0.103%)\n",
      "   -Testing: 122 images predicted correctly out of 194 (Accuracy: 62.887)%\n",
      "Epoch number: 108\n",
      "   -Training: 645.0 images predicted correctly out of 691 (Accuracy: 93.343%, Epoch Loss: 0.243%)\n",
      "   -Testing: 127 images predicted correctly out of 194 (Accuracy: 65.464)%\n",
      "Epoch number: 109\n",
      "   -Training: 645.0 images predicted correctly out of 691 (Accuracy: 93.343%, Epoch Loss: 0.196%)\n",
      "   -Testing: 130 images predicted correctly out of 194 (Accuracy: 67.010)%\n",
      "Epoch number: 110\n",
      "   -Training: 629.0 images predicted correctly out of 691 (Accuracy: 91.027%, Epoch Loss: 0.285%)\n",
      "   -Testing: 102 images predicted correctly out of 194 (Accuracy: 52.577)%\n",
      "Epoch number: 111\n",
      "   -Training: 647.0 images predicted correctly out of 691 (Accuracy: 93.632%, Epoch Loss: 0.204%)\n",
      "   -Testing: 128 images predicted correctly out of 194 (Accuracy: 65.979)%\n",
      "Epoch number: 112\n",
      "   -Training: 647.0 images predicted correctly out of 691 (Accuracy: 93.632%, Epoch Loss: 0.188%)\n",
      "   -Testing: 131 images predicted correctly out of 194 (Accuracy: 67.526)%\n",
      "Epoch number: 113\n",
      "   -Training: 644.0 images predicted correctly out of 691 (Accuracy: 93.198%, Epoch Loss: 0.168%)\n",
      "   -Testing: 134 images predicted correctly out of 194 (Accuracy: 69.072)%\n",
      "Epoch number: 114\n",
      "   -Training: 672.0 images predicted correctly out of 691 (Accuracy: 97.250%, Epoch Loss: 0.104%)\n",
      "   -Testing: 128 images predicted correctly out of 194 (Accuracy: 65.979)%\n",
      "Epoch number: 115\n",
      "   -Training: 670.0 images predicted correctly out of 691 (Accuracy: 96.961%, Epoch Loss: 0.092%)\n",
      "   -Testing: 135 images predicted correctly out of 194 (Accuracy: 69.588)%\n",
      "Epoch number: 116\n",
      "   -Training: 682.0 images predicted correctly out of 691 (Accuracy: 98.698%, Epoch Loss: 0.067%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 117\n",
      "   -Training: 679.0 images predicted correctly out of 691 (Accuracy: 98.263%, Epoch Loss: 0.047%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 118\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.049%)\n",
      "   -Testing: 143 images predicted correctly out of 194 (Accuracy: 73.711)%\n",
      "Epoch number: 119\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.044%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 120\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.030%)\n",
      "   -Testing: 142 images predicted correctly out of 194 (Accuracy: 73.196)%\n",
      "Epoch number: 121\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.023%)\n",
      "   -Testing: 147 images predicted correctly out of 194 (Accuracy: 75.773)%\n",
      "Epoch number: 122\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.017%)\n",
      "   -Testing: 142 images predicted correctly out of 194 (Accuracy: 73.196)%\n",
      "Epoch number: 123\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.015%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 124\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.023%)\n",
      "   -Testing: 142 images predicted correctly out of 194 (Accuracy: 73.196)%\n",
      "Epoch number: 125\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.030%)\n",
      "   -Testing: 142 images predicted correctly out of 194 (Accuracy: 73.196)%\n",
      "Epoch number: 126\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.022%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 127\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.035%)\n",
      "   -Testing: 137 images predicted correctly out of 194 (Accuracy: 70.619)%\n",
      "Epoch number: 128\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.038%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 129\n",
      "   -Training: 680.0 images predicted correctly out of 691 (Accuracy: 98.408%, Epoch Loss: 0.047%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 130\n",
      "   -Training: 676.0 images predicted correctly out of 691 (Accuracy: 97.829%, Epoch Loss: 0.070%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 131\n",
      "   -Training: 682.0 images predicted correctly out of 691 (Accuracy: 98.698%, Epoch Loss: 0.059%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 132\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.049%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 133\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.050%)\n",
      "   -Testing: 136 images predicted correctly out of 194 (Accuracy: 70.103)%\n",
      "Epoch number: 134\n",
      "   -Training: 681.0 images predicted correctly out of 691 (Accuracy: 98.553%, Epoch Loss: 0.055%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 135\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.047%)\n",
      "   -Testing: 135 images predicted correctly out of 194 (Accuracy: 69.588)%\n",
      "Epoch number: 136\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.035%)\n",
      "   -Testing: 139 images predicted correctly out of 194 (Accuracy: 71.649)%\n",
      "Epoch number: 137\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.039%)\n",
      "   -Testing: 140 images predicted correctly out of 194 (Accuracy: 72.165)%\n",
      "Epoch number: 138\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.032%)\n",
      "   -Testing: 145 images predicted correctly out of 194 (Accuracy: 74.742)%\n",
      "Epoch number: 139\n",
      "   -Training: 684.0 images predicted correctly out of 691 (Accuracy: 98.987%, Epoch Loss: 0.032%)\n",
      "   -Testing: 141 images predicted correctly out of 194 (Accuracy: 72.680)%\n",
      "Epoch number: 140\n",
      "   -Training: 685.0 images predicted correctly out of 691 (Accuracy: 99.132%, Epoch Loss: 0.029%)\n",
      "   -Testing: 144 images predicted correctly out of 194 (Accuracy: 74.227)%\n",
      "Epoch number: 141\n",
      "   -Training: 686.0 images predicted correctly out of 691 (Accuracy: 99.276%, Epoch Loss: 0.024%)\n",
      "   -Testing: 138 images predicted correctly out of 194 (Accuracy: 71.134)%\n",
      "Epoch number: 142\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.023%)\n",
      "   -Testing: 148 images predicted correctly out of 194 (Accuracy: 76.289)%\n",
      "Epoch number: 143\n",
      "   -Training: 689.0 images predicted correctly out of 691 (Accuracy: 99.711%, Epoch Loss: 0.011%)\n",
      "   -Testing: 147 images predicted correctly out of 194 (Accuracy: 75.773)%\n",
      "Epoch number: 144\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.010%)\n",
      "   -Testing: 149 images predicted correctly out of 194 (Accuracy: 76.804)%\n",
      "Epoch number: 145\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.019%)\n",
      "   -Testing: 146 images predicted correctly out of 194 (Accuracy: 75.258)%\n",
      "Epoch number: 146\n",
      "   -Training: 689.0 images predicted correctly out of 691 (Accuracy: 99.711%, Epoch Loss: 0.015%)\n",
      "   -Testing: 150 images predicted correctly out of 194 (Accuracy: 77.320)%\n",
      "Epoch number: 147\n",
      "   -Training: 687.0 images predicted correctly out of 691 (Accuracy: 99.421%, Epoch Loss: 0.016%)\n",
      "   -Testing: 137 images predicted correctly out of 194 (Accuracy: 70.619)%\n",
      "Epoch number: 148\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.022%)\n",
      "   -Testing: 146 images predicted correctly out of 194 (Accuracy: 75.258)%\n",
      "Epoch number: 149\n",
      "   -Training: 690.0 images predicted correctly out of 691 (Accuracy: 99.855%, Epoch Loss: 0.015%)\n",
      "   -Testing: 146 images predicted correctly out of 194 (Accuracy: 75.258)%\n",
      "Epoch number: 150\n",
      "   -Training: 688.0 images predicted correctly out of 691 (Accuracy: 99.566%, Epoch Loss: 0.018%)\n",
      "   -Testing: 142 images predicted correctly out of 194 (Accuracy: 73.196)%\n",
      "Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn(resnet18_model, training_loader, test_loader, loss_fn, optimizer, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e245409d-e120-4e8d-a5c5-49ec86e1769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "77.31958762886597\n"
     ]
    }
   ],
   "source": [
    "# Checks checkpoint information\n",
    "\n",
    "checkpoint = torch.load('Best-Model-Checkpoint.pth.tar')\n",
    "\n",
    "print(checkpoint['epoch'])\n",
    "print(checkpoint['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd7ce04-6c1f-4c8e-97f9-5018b217cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model with best accuracy\n",
    "\n",
    "checkpoint = torch.load('Best-Model-Checkpoint.pth.tar')\n",
    "resnet18_model = models.resnet18()\n",
    "num_ftrs = resnet18_model.fc.in_features\n",
    "num_classes = 6\n",
    "resnet18_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "resnet18_model.load_state_dict(checkpoint['model']) # optimizer not needed since it is only used during training to find best paramters\n",
    "\n",
    "torch.save(resnet18_model, 'Best-Model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5a497-fc9b-4c61-8308-c1118b1590f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
